import os
import csv
import psycopg2
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

from config import (
    db_config,
    point_csv,
    log_dir,
    image_dir,
    query_table,
    topKs,
    ivfflat_probesList,
    hnsw_ef_search,
    groundtruth_table,
    work_mem,
    maintenance_work_mem
)

# ivfflat probes æ‰¾ä¸åˆ°åŒ¹é…é¡¹æ—¶çš„é»˜è®¤å€¼
ivfflat_probes_default = 35


def log(msg: str):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {msg}")


def ensure_dir(path: str):
    if not os.path.exists(path):
        os.makedirs(path)


def load_query_vectors(file_path: str):
    """
    point_csv: é»˜è®¤ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
    æ¯è¡Œå– row[:128] ä½œä¸ºå‘é‡ï¼ˆä¿æŒä½ åŸé€»è¾‘ï¼‰
    """
    log(f"ğŸ”¹ åŠ è½½æŸ¥è¯¢å‘é‡: {file_path}")
    vectors = []
    with open(file_path, newline="") as f:
        reader = csv.reader(f)
        next(reader)  # skip header
        for row in reader:
            vec = list(map(float, row[:128]))
            vectors.append(vec)
    log(f"  -> åŠ è½½å®Œæˆï¼Œå…± {len(vectors)} ä¸ªæŸ¥è¯¢å‘é‡")
    return vectors


def compute_recall(result_ids, gt_ids):
    if not gt_ids:
        return 0.0
    return len(set(result_ids) & set(gt_ids)) / len(gt_ids)


def find_groundtruth_table(query_table_name: str):
    for gt_table, derived_tables in groundtruth_table.items():
        if query_table_name in derived_tables:
            return gt_table
    return None


def infer_ivfflat_probes_for_table(table_name: str) -> int:
    """
    ä¸¥æ ¼æŒ‰è¡¨ååŒ…å« '_ivfflat' åˆ¤æ–­ IVF è¡¨ï¼Œç„¶åå†ä» ivfflat_probesList æ¨æ–­ probesï¼š
    - è‹¥ table_name æ˜¯ xxx_ivfflatï¼Œåˆ™ base_name=xxx
    - ä¼˜å…ˆ base_name ç²¾ç¡®åŒ¹é… ivfflat_probesList
    - å¦åˆ™åšå­ä¸²åŒ¹é…
    - æ‰¾ä¸åˆ°å°±ç”¨é»˜è®¤ ivfflat_probes_default
    """
    base_name = table_name
    if base_name.endswith("_ivfflat"):
        base_name = base_name[: -len("_ivfflat")]

    if base_name in ivfflat_probesList:
        return int(ivfflat_probesList[base_name])

    for key, val in ivfflat_probesList.items():
        if key in base_name or base_name in key:
            return int(val)

    return int(ivfflat_probes_default)


def get_first_col_name_and_value(table_name: str):
    """
    ä¸¥æ ¼æŒ‰è¡¨ååç¼€åˆ¤æ–­ï¼š
      - åŒ…å« '_hnsw'    -> ç¬¬ä¸€åˆ—å«ä¹‰æ˜¯ efï¼Œå€¼å– config.hnsw_ef_search
      - åŒ…å« '_ivfflat' -> ç¬¬ä¸€åˆ—å«ä¹‰æ˜¯ ivfflat_probesListï¼Œå€¼å– probes
      - éç´¢å¼•è¡¨ -> è¿”å› (None, None)ï¼ˆä¸å†™ CSVï¼‰
    """
    if "_hnsw" in table_name:
        return "ef", int(hnsw_ef_search)
    if "_ivfflat" in table_name:
        return "ivfflat_probesList", int(infer_ivfflat_probes_for_table(table_name))
    return None, None


def execute_query(cursor, table: str, vec, k: int, ivfflat_probes_value=None):
    """
    ä¿æŒ EXPLAIN ANALYZE + å®é™…æŸ¥è¯¢ é€»è¾‘ä¸å˜
    ä»…å°†å‚æ•°è®¾ç½®åˆ¤æ–­æ”¹ä¸ºä¸¥æ ¼ '_ivfflat' / '_hnsw'
    """
    emb_str = ",".join(map(str, vec))

    try:
        cursor.execute(f"SET work_mem = '{work_mem}';")
        cursor.execute(f"SET maintenance_work_mem = '{maintenance_work_mem}';")

        if "_ivfflat" in table and ivfflat_probes_value is not None:
            cursor.execute(f"SET ivfflat.probes = {ivfflat_probes_value};")
        elif "_hnsw" in table:
            cursor.execute(f"SET hnsw.ef_search = {hnsw_ef_search};")
    except Exception as e:
        log(f"âŒ å‚æ•°è®¾ç½®å¤±è´¥: {e}")
        cursor.execute("ROLLBACK;")

    query = f"""
        SELECT id FROM {table}
        ORDER BY embedding <-> '[{emb_str}]'
        LIMIT {k};
    """

    try:
        explain_query = f"EXPLAIN ANALYZE {query.strip()}"
        cursor.execute(explain_query)
        plan_lines = cursor.fetchall()
        time_line = [line[0] for line in plan_lines if "Execution Time" in line[0]]
        exec_time = float(time_line[0].split(":")[1].strip().split()[0]) if time_line else -1.0

        cursor.execute(query)
        ids = [row[0] for row in cursor.fetchall()]
        return ids, exec_time
    except Exception as e:
        log(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        cursor.execute("ROLLBACK;")
        return [], -1.0


def run():
    log("=== ğŸš€ å¯åŠ¨æŸ¥è¯¢è¯„ä¼°è„šæœ¬ï¼ˆå†™ CSVï¼šä»…ç´¢å¼•è¡¨ _ivfflat/_hnswï¼›ä¸å†å†™ JSONï¼‰ ===")
    ensure_dir(log_dir)
    ensure_dir(image_dir)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    cur_log_dir = os.path.join(log_dir, timestamp)
    cur_img_dir = os.path.join(image_dir, timestamp)
    ensure_dir(cur_log_dir)
    ensure_dir(cur_img_dir)

    log(f"ğŸ“ æ—¥å¿—ä¿å­˜è·¯å¾„: {cur_log_dir}")
    log(f"ğŸ–¼ï¸ å›¾åƒä¿å­˜è·¯å¾„: {cur_img_dir}")

    vectors = load_query_vectors(point_csv)

    conn = psycopg2.connect(**db_config)
    cursor = conn.cursor()

    for k in topKs:
        log(f"\n=== ğŸ” Top{k} æŸ¥è¯¢è¯„ä¼°å¼€å§‹ ===")

        recalls_per_table = {table: [] for table in query_table}
        times_per_table = {table: [] for table in query_table}

        # æ˜ç»† txtï¼ˆä¿ç•™ï¼‰
        detail_txt_path = os.path.join(cur_log_dir, f"top{k}_details.txt")
        with open(detail_txt_path, "w", encoding="utf-8") as detail_log:
            detail_log.write("QueryIndex,Table,ExecTime(ms),Recall\n")

            # âœ… KNN id_list CSVï¼šä»…å†™ç´¢å¼•è¡¨ï¼ˆ_ivfflat/_hnswï¼‰
            knn_csv_path = os.path.join(cur_log_dir, f"top{k}_knn_ids.csv")
            with open(knn_csv_path, "w", newline="", encoding="utf-8") as knn_csv:
                writer = csv.writer(knn_csv)
                writer.writerow(["ef/ivfflat_probesList", "k", "query", "id_list"])

                for i, vec in enumerate(vectors):
                    log("\n" + "-" * 70)
                    log(f"â¡ï¸ æŸ¥è¯¢å‘é‡ query={i}ï¼ˆ0-basedï¼‰ğŸ”¹ å½“å‰ TopK: {k}")

                    for table in query_table:
                        gt_table = find_groundtruth_table(table)
                        if gt_table is None:
                            log(f"âš ï¸ è¡¨ {table} æ²¡æœ‰å¯¹åº” groundtruthï¼Œè·³è¿‡")
                            continue

                        # groundtruthï¼ˆæŒ‰ä½ åŸé€»è¾‘ï¼šgt_table é€šå¸¸æ˜¯ base/flatï¼‰
                        gt_ids, _ = execute_query(cursor, gt_table, vec, k)

                        # å½“å‰è¡¨çš„ probesï¼ˆä»… ivfflat éœ€è¦ï¼‰
                        current_ivfflat_probes = None
                        if "_ivfflat" in table:
                            current_ivfflat_probes = infer_ivfflat_probes_for_table(table)

                        # å®é™…æŸ¥è¯¢
                        result_ids, exec_time = execute_query(
                            cursor,
                            table,
                            vec,
                            k,
                            ivfflat_probes_value=current_ivfflat_probes
                        )

                        recall = compute_recall(result_ids, gt_ids)

                        log(f"ğŸ“Œ è¡¨: {table} (gt={gt_table}) â±ï¸ {exec_time:.2f} ms | âœ… recall={recall:.4f}")

                        recalls_per_table[table].append(recall)
                        times_per_table[table].append(exec_time)
                        detail_log.write(f"{i},{table},{exec_time:.2f},{recall:.4f}\n")

                        # âœ… åªå†™ç´¢å¼•è¡¨ï¼šè¡¨åå¿…é¡»åŒ…å« _ivfflat æˆ– _hnsw
                        col_name, col_value = get_first_col_name_and_value(table)
                        if col_name is None:
                            continue  # éç´¢å¼•è¡¨ä¸å†™å…¥ CSV

                        id_list_str = " ".join(map(str, result_ids))
                        writer.writerow([col_value, k, i, id_list_str])

        log(f"ğŸ§¾ Top{k} KNN CSV å·²ä¿å­˜ï¼ˆä»…ç´¢å¼•è¡¨ï¼‰: {os.path.join(cur_log_dir, f'top{k}_knn_ids.csv')}")

        # summary mdï¼ˆä¿ç•™ï¼‰
        summary_md_path = os.path.join(cur_log_dir, f"top{k}_summary.md")
        with open(summary_md_path, "w", encoding="utf-8") as summary:
            summary.write(f"# Top{k} æŸ¥è¯¢æ±‡æ€»\n\n")
            summary.write("| Table | Total Time (ms) | Avg Time (ms) | Avg Recall |\n")
            summary.write("|-------|----------------|----------------|-------------|\n")
            for table in query_table:
                total_time = sum(times_per_table[table])
                avg_time = total_time / len(times_per_table[table]) if times_per_table[table] else 0.0
                avg_recall = (
                    sum(recalls_per_table[table]) / len(recalls_per_table[table])
                    if recalls_per_table[table] else 0.0
                )
                summary.write(f"| {table} | {total_time:.2f} | {avg_time:.2f} | {avg_recall:.4f} |\n")

        # ç»˜å›¾ï¼ˆä¿ç•™ï¼‰
        try:
            x = np.arange(len(query_table))
            total_times = [sum(times_per_table[table]) for table in query_table]
            avg_recalls = [
                (sum(recalls_per_table[table]) / len(recalls_per_table[table])) if recalls_per_table[table] else 0.0
                for table in query_table
            ]

            fig, ax1 = plt.subplots(figsize=(12, 6))
            ax1.bar(x, total_times, color="skyblue", label="Total Query Time (ms)")
            ax1.set_ylabel("Total Query Time (ms)", color="skyblue")
            ax1.tick_params(axis="y", labelcolor="skyblue")

            ax2 = ax1.twinx()
            ax2.plot(x, avg_recalls, color="orange", marker="o", label="Average Recall")
            ax2.set_ylabel("Average Recall", color="orange")
            ax2.tick_params(axis="y", labelcolor="orange")

            plt.xticks(x, query_table, rotation=30, ha="right")
            plt.title(f"Top{k} Query - Total Time & Avg Recall")
            fig.tight_layout()

            img_path = os.path.join(cur_img_dir, f"top{k}_summary.png")
            plt.savefig(img_path)
            plt.close()
            log(f"ğŸ“Š å›¾åƒä¿å­˜: {img_path}")
        except Exception as e:
            log(f"âš ï¸ ç»˜å›¾å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œåç»­ä»£ç ")

    cursor.close()
    conn.close()
    log("âœ… æ‰€æœ‰æŸ¥è¯¢å®Œæˆï¼Œè¿æ¥å·²å…³é—­")
    log(f"ğŸ“ æ—¥å¿—å­˜å‚¨åœ¨: {cur_log_dir}")
    log(f"ğŸ–¼ï¸ å›¾åƒå­˜å‚¨åœ¨: {cur_img_dir}")


if __name__ == "__main__":
    run()
